Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	metadata_untampered_bulk_primary_cells_with_data
	1

[Mon Jun  1 12:21:15 2020]
rule metadata_untampered_bulk_primary_cells_with_data:
    input: /tier2/deweylab/mnbernstein/phenotyping_environments/metasra_1-4.annot_10/experiment_sets/untampered_bulk_primary_cells_with_data.json
    output: /tier2/deweylab/mnbernstein/phenotyping_environments/metasra_1-4.annot_10/datasets/untampered_bulk_primary_cells_with_data/experiment_to_study.json, /tier2/deweylab/mnbernstein/phenotyping_environments/metasra_1-4.annot_10/datasets/untampered_bulk_primary_cells_with_data/experiment_to_tags.json
    jobid: 0

[Mon Jun  1 12:21:16 2020]
Finished job 0.
1 of 1 steps (100%) done
Complete log: /ua/mnbernstein/projects/tbcp/cello_dev/build_dataset/.snakemake/log/2020-06-01T122114.940082.snakemake.log
